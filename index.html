<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lassi: Llama Assistive-bot for Speech and Sign language Interaction</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: white;
            color: black;
            line-height: 1.6;
        }

        .container {
            width: 80%;
            margin: 20px auto;
            padding: 20px;
        }

        h1 {
            text-align: center;
            font-size: 2.5em;
            margin-bottom: 40px;
        }

        h2 {
            border-bottom: 2px solid #333;
            padding-bottom: 5px;
            margin-bottom: 20px;
            font-size: 1.8em;
        }

        section {
            margin-bottom: 50px;
        }

        .image-placeholder,
        .video-placeholder {
            background-color: white;
            text-align: center;
            padding: 50px 0;
            margin: 20px 0;
        }

        .image-placeholder p,
        .video-placeholder p {
            color: white;
            font-size: 1.2em;
        }
    </style>
</head>

<body>

    <div class="container">
        <h1>LASSI: Llama Assistive-bot for Speech and Sign language Interaction</h1>

        <section id="introduction">
            <h2>Introduction</h2>
            <p>
              The project centers around developing a versatile and intelligent robot, powered by the LLaMA 3.1 model, designed to assist people in various settings such as hospitals, apartments, and other environments. At the heart of this innovation is LLaMA 3.1, which acts as the central brain, enabling the robot to understand and process a wide range of inputs, including sign language, spoken language, and visual data.
              
              The robot is equipped with multiple advanced models to achieve this. Sign language is translated into spoken language through a specialized detection system, transforming gestures into understandable sentences. Whisper AI, a robust speech recognition system, transcribes spoken language into text with remarkable accuracy, even in noisy environments. These inputs are then processed by the LLaMA 3.1 model, which makes critical decisions regarding the robot's next actions.
              
              To navigate and interact within its environment, the robot utilizes an object detection model and the RTAB-Map for real-time SLAM (Simultaneous Localization and Mapping), creating a detailed 3D map of its surroundings. The object detection model identifies and recognizes objects, generating prompts for the LLaMA model, which in turn formulates waypoints for navigation. These waypoints are then used by the ROS2 navigation stack to guide the robot effectively.
              
              The integration of these technologies allows the robot to be highly adaptive and user-friendly, making it a valuable tool for assisting people in various contexts. Whether aiding patients in hospitals, helping residents in apartments, or assisting in other public or private spaces, this robot is designed to be accessible and beneficial to everyone, demonstrating the immense potential of AI-driven assistance in everyday life.</p>
        </section>

        <section id="methodology">
            <h2>Methodology</h2>
            <p>LASSI is the overarching project that aims to create an intelligent, autonomous robot capable of understanding and processing multiple types of inputs to assist users in various environments. 
              The core idea revolves around integrating advanced AI models to provide seamless interaction, whether through sign language, spoken words, or visual cues. The robot is designed to adapt to diverse scenarios, offering valuable assistance in settings such as hospitals, apartments, and more, making it a versatile tool for enhancing daily life. Below we have shown diagram demonstrating our entire system block by block.</p>
        </section>

        <div class="image-placeholder">
            <img src="images/flow.png" alt="Image Placeholder">
        </div>

        <section id="results">
            <h2>Results</h2>
            <p>The results of the study are presented in this section.</p>
        </section>

        <div class="video-placeholder">
            <video width="640" height="360" controls>
                <source src="videos/sign_language_detection.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <div style="text-align: center; margin-top: -20px;">
                <p>Sign Language Detection</p> 
            </div>
        </div>
        
        <div class="video-placeholder">
            <video width="640" height="360" controls>
                <source src="videos/llama.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
            <div style="text-align: center;">
                <p>Speech Recognition</p>
            </div>
        </div>        
</body>

</html>
